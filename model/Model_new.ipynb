{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (use your actual file path here)\n",
    "df = pd.read_excel('transformed_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset in a format suitable for fine-tuning (prompt and response)\n",
    "train_data = []\n",
    "for index, row in df.iterrows():\n",
    "    prompt = row['User input English-in English letters']\n",
    "    response = row['System output']\n",
    "    train_data.append({\"prompt\": prompt, \"response\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Domain</th>\n",
       "      <th>User input English-in English letters</th>\n",
       "      <th>System output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green Grow Farms</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>Executive Summary: Green Grow Farms is a newly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holiday Mansion</td>\n",
       "      <td>Tourism and Hospitality</td>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary: \\nHoliday Mansion, a luxu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC Textiles</td>\n",
       "      <td>Manufacturing and Exporting</td>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary\\nABC Manufacturing is a le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PrecisionTools Ltd</td>\n",
       "      <td>Manufacturing and Exporting</td>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary\\n\\nPrecisionTools Ltd spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Navi</td>\n",
       "      <td>Manufacturing and Exporting</td>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary\\nNavi is an emerging cloth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Business Name                       Domain  \\\n",
       "0    Green Grow Farms                 Agriculture    \n",
       "1     Holiday Mansion      Tourism and Hospitality   \n",
       "2        ABC Textiles  Manufacturing and Exporting   \n",
       "3  PrecisionTools Ltd  Manufacturing and Exporting   \n",
       "4                Navi  Manufacturing and Exporting   \n",
       "\n",
       "               User input English-in English letters  \\\n",
       "0  Generate business report contents for the comp...   \n",
       "1  Generate business report contents for the comp...   \n",
       "2  Generate business report contents for the comp...   \n",
       "3  Generate business report contents for the comp...   \n",
       "4  Generate business report contents for the comp...   \n",
       "\n",
       "                                       System output  \n",
       "0  Executive Summary: Green Grow Farms is a newly...  \n",
       "1  \\nExecutive Summary: \\nHoliday Mansion, a luxu...  \n",
       "2  \\nExecutive Summary\\nABC Manufacturing is a le...  \n",
       "3  \\nExecutive Summary\\n\\nPrecisionTools Ltd spec...  \n",
       "4  \\nExecutive Summary\\nNavi is an emerging cloth...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>Executive Summary: Green Grow Farms is a newly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary: \\nHoliday Mansion, a luxu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary\\nABC Manufacturing is a le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary\\n\\nPrecisionTools Ltd spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nExecutive Summary\\nNavi is an emerging cloth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\n\\nCompany Overview:\\n\\nLanka Reads Bookshop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\n\\nCompany Overview\\nTechSolve Innovations is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\n1. Company Overview\\nLifeCare Wellness Cente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nCompany Overview\\nSoloMagic is an establishe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Generate business report contents for the comp...</td>\n",
       "      <td>\\nCompany Overview\\nAncientWaves Resort, locat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   Generate business report contents for the comp...   \n",
       "1   Generate business report contents for the comp...   \n",
       "2   Generate business report contents for the comp...   \n",
       "3   Generate business report contents for the comp...   \n",
       "4   Generate business report contents for the comp...   \n",
       "..                                                ...   \n",
       "95  Generate business report contents for the comp...   \n",
       "96  Generate business report contents for the comp...   \n",
       "97  Generate business report contents for the comp...   \n",
       "98  Generate business report contents for the comp...   \n",
       "99  Generate business report contents for the comp...   \n",
       "\n",
       "                                             response  \n",
       "0   Executive Summary: Green Grow Farms is a newly...  \n",
       "1   \\nExecutive Summary: \\nHoliday Mansion, a luxu...  \n",
       "2   \\nExecutive Summary\\nABC Manufacturing is a le...  \n",
       "3   \\nExecutive Summary\\n\\nPrecisionTools Ltd spec...  \n",
       "4   \\nExecutive Summary\\nNavi is an emerging cloth...  \n",
       "..                                                ...  \n",
       "95  \\n\\nCompany Overview:\\n\\nLanka Reads Bookshop ...  \n",
       "96  \\n\\nCompany Overview\\nTechSolve Innovations is...  \n",
       "97  \\n1. Company Overview\\nLifeCare Wellness Cente...  \n",
       "98  \\nCompany Overview\\nSoloMagic is an establishe...  \n",
       "99  \\nCompany Overview\\nAncientWaves Resort, locat...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared for fine-tuning and saved as 'train_data.json'.\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuning data as a JSON file (Hugging Face prefers this format)\n",
    "train_df.to_json('train_data.json', orient='records', lines=True)\n",
    "\n",
    "print(\"Dataset prepared for fine-tuning and saved as 'train_data.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\Document_Generator\\model\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 2901.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the JSON file\n",
    "train_dataset = load_dataset('json', data_files='train_data.json', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pad_token to eos_token (End of Sequence token)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/100 [00:00<?, ? examples/s]Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Keyword arguments {'pad_token_id': 50256} not recognized.\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 199.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['prompt'], padding=\"max_length\", truncation=True, max_length=512, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Apply tokenization\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Tokenization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data collator (handles batching and padding for variable-length inputs)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",          # Output directory\n",
    "    overwrite_output_dir=True,      # Overwrite the output dir\n",
    "    num_train_epochs=3,             # Number of training epochs\n",
    "    per_device_train_batch_size=4,  # Batch size per device\n",
    "    save_steps=10_000,              # Save checkpoint every 10,000 steps\n",
    "    save_total_limit=2,             # Keep the latest 2 models\n",
    "    logging_dir=\"./logs\",           # Directory for logs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [23:57<00:00, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1437.3525, 'train_samples_per_second': 0.209, 'train_steps_per_second': 0.052, 'train_loss': 2.1505721028645834, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75, training_loss=2.1505721028645834, metrics={'train_runtime': 1437.3525, 'train_samples_per_second': 0.209, 'train_steps_per_second': 0.052, 'total_flos': 78387609600000.0, 'train_loss': 2.1505721028645834, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start fine-tuning\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "trainer.save_model('./fine_tuned_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_model')\n",
    "\n",
    "print(\"Fine-tuning complete and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "model = GPT2LMHeadModel.from_pretrained('./fine_tuned_model')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./fine_tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt for testing\n",
    "prompt = \"Generate business report contents for the company 'ABC Corp.' based on the following scope: Our agricultural activities focus on using natural fertilizers, indoor farming, and methods that protect biodiversity. We aim to increase our yield by using modern technology. We estimate our first-year revenue to be $50,000, with an expected annual growth rate of 20%. According to our timeline, the first harvest is expected within 6 months, and full-scale production is planned to begin within a year. Generate the following sections:- Executive Summary - Industry Overview and Trends - Problem Statement - Proposed Solution - Market Analysis - Sustainable Practices - Supply Chain and Distribution - Financial Projections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a prediction\n",
    "output = model.generate(inputs['input_ids'], max_length=700, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Business Report Contents:\n",
      "Generate business report contents for the company 'ABC Corp.' based on the following scope: Our agricultural activities focus on using natural fertilizers, indoor farming, and methods that protect biodiversity. We aim to increase our yield by using modern technology. We estimate our first-year revenue to be $50,000, with an expected annual growth rate of 20%. According to our timeline, the first harvest is expected within 6 months, and full-scale production is planned to begin within a year. Generate the following sections:- Executive Summary - Industry Overview and Trends - Problem Statement - Proposed Solution - Market Analysis - Sustainable Practices - Supply Chain and Distribution - Financial Projections - Implementation Timeline - Conclusion\n",
      "Generate the following sections:- Executive Summary\n",
      "- Industry Overview and Trends\n",
      "- Problem Statement\n",
      "- Proposed Solution\n",
      "- Supply Chain and Distribution\n",
      "- Financial Projections\n",
      "- Implementation Timeline\n",
      "- Conclusion\n",
      "Generate the following sections:- Part 1: Industry Overview and Trends\n",
      "- Part 2: Supply Chain and Distribution\n",
      "- Part 3: Implementation Timeline\n",
      "- Conclusion\n",
      "I want to make a business proposal for Harvest Harvest Farms. Harvest Harvest Farms is a new farming operation based in the heart of the city of Lhasa, located in the heart of the country. We are seeking funding to expand our operations and expand our production capabilities. We plan to use organic fertilizers, organic farming techniques, and sustainable practices to enhance our yield and profitability. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion.\n"
     ]
    }
   ],
   "source": [
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated Business Report Contents:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 5.639610290527344\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = GPT2LMHeadModel.from_pretrained('./fine_tuned_model')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./fine_tuned_model')\n",
    "\n",
    "# Example input for evaluation\n",
    "prompt = \"Generate business report contents for the company 'ABC Corp.' based on the following scope: Our agricultural activities focus on using natural fertilizers, indoor farming, and methods that protect biodiversity. We aim to increase our yield by using modern technology. We estimate our first-year revenue to be $50,000, with an expected annual growth rate of 20%. According to our timeline, the first harvest is expected within 6 months, and full-scale production is planned to begin within a year. Generate the following sections:- Executive Summary - Industry Overview and Trends - Problem Statement - Proposed Solution - Market Analysis - Sustainable Practices - Supply Chain and Distribution - Financial Projections\"\n",
    "\n",
    "# Tokenize the input prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward pass to get loss\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    loss = outputs.loss\n",
    "\n",
    "# Compute Perplexity\n",
    "perplexity = torch.exp(loss)\n",
    "print(f\"Perplexity: {perplexity.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 5.615242822883281e-79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\Document_Generator\\model\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Example reference and generated text\n",
    "reference = \"Executive Summary: Green Grow Farms is a newly established business focusing on sustainable agricultural practices using organic fertilizers and modern indoor farming techniques to maximize crop yield. Industry Overview and Trends: The agricultural industry in Sri Lanka is moving towards more sustainable and eco-friendly farming practices to meet growing local and international demand. Problem Statement: The rising cost of conventional farming inputs and environmental degradation calls for more sustainable farming techniques. Proposed Agricultural Solution: Green Grow Farms provides innovative farming techniques, including organic fertilizers, controlled indoor farming systems, and practices to preserve biodiversity. Market Analysis: The demand for organic products is on the rise, driven by health-conscious consumers both locally and internationally. Sustainable Farming Practices: The farm will use environmentally friendly methods, focusing on organic inputs, water conservation, and crop rotation to ensure long-term soil fertility. Supply Chain and Distribution: Partnerships with local retailers, organic food suppliers, and export markets are planned to distribute produce efficiently. Financial Projections: Estimated revenue in the first year is $50,000, with anticipated growth of 20% per year. Implementation Timeline: The first harvest is expected within 6 months, with full-scale production to follow within a year. Conclusion: Green Grow Farms aims to contribute to the sustainable agricultural landscape in Sri Lanka, offering eco-friendly solutions to modern farming challenges\"\n",
    "generated = \"I want to make a business proposal for Harvest Harvest Farms. Harvest Harvest Farms is a new farming operation based in the heart of the city of Lhasa, located in the heart of the country. We are seeking funding to expand our operations and expand our production capabilities. We plan to use organic fertilizers, organic farming techniques, and sustainable practices to enhance our yield and profitability. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil quality and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion. We will also use organic fertilizers to enhance our soil fertility and reduce soil erosion.\"\n",
    "\n",
    "# Tokenize the sentences (split by words)\n",
    "reference_tokens = reference.split()\n",
    "generated_tokens = generated.split()\n",
    "\n",
    "# Compute BLEU score\n",
    "score = sentence_bleu([reference_tokens], generated_tokens)\n",
    "print(f\"BLEU Score: {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
